{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_MixUp_ICLR2018.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNswzraSc2fFqthdxsA/ADW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OUCTheoryGroup/colab_demo/blob/master/11_MixUp_ICLR2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrL50GxCZRXB"
      },
      "source": [
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as datasets\r\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubfP27w0a7qj"
      },
      "source": [
        "# LeNet 模型\r\n",
        "class LeNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(LeNet, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\r\n",
        "        self.fc2   = nn.Linear(120, 84)\r\n",
        "        self.fc3   = nn.Linear(84, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = F.relu(self.conv1(x))\r\n",
        "        out = F.max_pool2d(out, 2)\r\n",
        "        out = F.relu(self.conv2(out))\r\n",
        "        out = F.max_pool2d(out, 2)\r\n",
        "        out = out.view(out.size(0), -1)\r\n",
        "        out = F.relu(self.fc1(out))\r\n",
        "        out = F.relu(self.fc2(out))\r\n",
        "        out = self.fc3(out)\r\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoCDBZPPeBhm"
      },
      "source": [
        "def mixup_data(x, y, alpha=1.0):\r\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\r\n",
        "    if alpha > 0:\r\n",
        "        lam = np.random.beta(alpha, alpha)\r\n",
        "    else:\r\n",
        "        lam = 1\r\n",
        "\r\n",
        "    batch_size = x.size()[0]\r\n",
        "    index = torch.randperm(batch_size).cuda()\r\n",
        "\r\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\r\n",
        "    y_a, y_b = y, y[index]\r\n",
        "    return mixed_x, y_a, y_b, lam\r\n",
        "\r\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\r\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0TWxD01Znl4",
        "outputId": "3aecffc1-22ba-4379-93ff-93fbc52ef99e"
      },
      "source": [
        "transform_train = transforms.Compose([ transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\r\n",
        "transform_test  = transforms.Compose([ transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\r\n",
        "\r\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True,   transform=transform_train)\r\n",
        "testset  = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_test)\r\n",
        "\r\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True,  num_workers=2)\r\n",
        "testloader  = torch.utils.data.DataLoader(testset,  batch_size=64, shuffle=False, num_workers=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d-qJE2NdfE8"
      },
      "source": [
        "# MixUp的重要参数 alpha\r\n",
        "alpha = 1.0\r\n",
        "\r\n",
        "net = LeNet().cuda()\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D-JWGIKechw",
        "outputId": "85840eb6-1963-4cfe-9817-91e940216e84"
      },
      "source": [
        "# 网络训练\r\n",
        "net.train()\r\n",
        "\r\n",
        "for epoch in range(30):\r\n",
        "    train_loss = 0\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    \r\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\r\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\r\n",
        "        inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha)\r\n",
        "        inputs, targets_a, targets_b = map(Variable, (inputs, targets_a, targets_b))\r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\r\n",
        "        train_loss += loss.data\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        total += targets.size(0)\r\n",
        "        correct += (lam * predicted.eq(targets_a.data).cpu().sum().float()\r\n",
        "                    + (1 - lam) * predicted.eq(targets_b.data).cpu().sum().float())\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "    print('Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)' \r\n",
        "        % (epoch+1, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "# 网络测试\r\n",
        "\r\n",
        "net.eval()\r\n",
        "test_loss = 0\r\n",
        "correct = 0\r\n",
        "total = 0\r\n",
        "for batch_idx, (inputs, targets) in enumerate(testloader):\r\n",
        "    inputs, targets = inputs.cuda(), targets.cuda()\r\n",
        "    inputs, targets = Variable(inputs, volatile=True), Variable(targets)\r\n",
        "    outputs = net(inputs)\r\n",
        "    loss = criterion(outputs, targets)\r\n",
        "\r\n",
        "    test_loss += loss.data\r\n",
        "    _, predicted = torch.max(outputs.data, 1)\r\n",
        "    total += targets.size(0)\r\n",
        "    correct += predicted.eq(targets.data).cpu().sum()\r\n",
        "\r\n",
        "print(' Test Accuracy: %.3f' % (100.*correct/total))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Loss: 1.546 | Acc: 49.334% (24667/50000)\n",
            "Epoch: 2 | Loss: 1.530 | Acc: 49.744% (24872/50000)\n",
            "Epoch: 3 | Loss: 1.556 | Acc: 48.919% (24459/50000)\n",
            "Epoch: 4 | Loss: 1.545 | Acc: 49.320% (24660/50000)\n",
            "Epoch: 5 | Loss: 1.542 | Acc: 49.199% (24599/50000)\n",
            "Epoch: 6 | Loss: 1.533 | Acc: 49.795% (24897/50000)\n",
            "Epoch: 7 | Loss: 1.535 | Acc: 49.555% (24777/50000)\n",
            "Epoch: 8 | Loss: 1.521 | Acc: 50.162% (25080/50000)\n",
            "Epoch: 9 | Loss: 1.517 | Acc: 50.542% (25271/50000)\n",
            "Epoch: 10 | Loss: 1.531 | Acc: 49.998% (24998/50000)\n",
            "Epoch: 11 | Loss: 1.516 | Acc: 50.587% (25293/50000)\n",
            "Epoch: 12 | Loss: 1.526 | Acc: 50.290% (25144/50000)\n",
            "Epoch: 13 | Loss: 1.503 | Acc: 51.269% (25634/50000)\n",
            "Epoch: 14 | Loss: 1.522 | Acc: 50.494% (25247/50000)\n",
            "Epoch: 15 | Loss: 1.515 | Acc: 50.790% (25394/50000)\n",
            "Epoch: 16 | Loss: 1.496 | Acc: 51.454% (25727/50000)\n",
            "Epoch: 17 | Loss: 1.521 | Acc: 50.713% (25356/50000)\n",
            "Epoch: 18 | Loss: 1.505 | Acc: 51.051% (25525/50000)\n",
            "Epoch: 19 | Loss: 1.497 | Acc: 51.494% (25747/50000)\n",
            "Epoch: 20 | Loss: 1.489 | Acc: 51.802% (25900/50000)\n",
            "Epoch: 21 | Loss: 1.483 | Acc: 52.079% (26039/50000)\n",
            "Epoch: 22 | Loss: 1.489 | Acc: 51.971% (25985/50000)\n",
            "Epoch: 23 | Loss: 1.495 | Acc: 51.445% (25722/50000)\n",
            "Epoch: 24 | Loss: 1.494 | Acc: 51.531% (25765/50000)\n",
            "Epoch: 25 | Loss: 1.493 | Acc: 51.801% (25900/50000)\n",
            "Epoch: 26 | Loss: 1.481 | Acc: 52.194% (26096/50000)\n",
            "Epoch: 27 | Loss: 1.496 | Acc: 51.624% (25812/50000)\n",
            "Epoch: 28 | Loss: 1.481 | Acc: 52.353% (26176/50000)\n",
            "Epoch: 29 | Loss: 1.472 | Acc: 52.560% (26279/50000)\n",
            "Epoch: 30 | Loss: 1.472 | Acc: 52.652% (26326/50000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Test Accuracy: 65.350\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}