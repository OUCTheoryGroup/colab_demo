{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 - 使用VGG模型进行猫狗大战",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OUCTheoryGroup/pytorch_demo/blob/master/01_Using_CNN_for_dogs_vs_cats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A4dM4oaFnTb",
        "colab_type": "text"
      },
      "source": [
        "##使用VGG模型进行猫狗大战\n",
        "\n",
        "原文见：https://github.com/mlelarge/dataflowr/blob/master/CEA_EDF_INRIA/01_intro_DLDIY_colab.ipynb\n",
        "\n",
        "结合自己的理解，有一定的修改。在本教程中，我们将建一个模型来完成 Kaggle 中的猫狗大战竞赛题目。在这个比赛中，有25000张标记好的猫和狗的图片用做训练，有12500张图片用做测试。这个竞赛是2013年开展的，如果你能够达到80%的准确率，在当年是一个 state-of-the-art 的成绩。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_iVLlwfD54x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import time\n",
        "import json\n",
        "\n",
        "\n",
        "# 判断是否存在GPU设备\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTQfQJaQGPsR",
        "colab_type": "text"
      },
      "source": [
        "## 1. 下载数据\n",
        "\n",
        "Jeremy Howard 提供了数据的下载，链接为：http://files.fast.ai/data/dogscats.zip \n",
        "\n",
        "在他整理的数据集中，猫和狗的图片放在单独的文件夹中， 同时还提供了一个Validation数据。如果没有GPU设备，请减少用做训练的图像数据量即可。\n",
        "\n",
        "因为这个代码需要在colab上跑，速度会相对较慢。因此，我们重新整理了数据，制作了新的数据集，训练集包含1800张图(猫的图片900张，狗的图片900张)，测试集包含2000张图。下载地址为：http://fenggao-image.stor.sinaapp.com/dogscats.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB2o6QSpGcBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget http://fenggao-image.stor.sinaapp.com/dogscats.zip\n",
        "! unzip dogscats.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWtes6tGHF-m",
        "colab_type": "text"
      },
      "source": [
        "## 2. 数据处理\n",
        "\n",
        "datasets 是 torchvision 中的一个包，可以用做加载图像数据。它可以以多线程（multi-thread）的形式从硬盘中读取数据，使用 mini-batch 的形式，在网络训练中向 GPU 输送。在使用CNN处理图像时，需要进行预处理。图片将被整理成 $224\\times 224 \\times 3$ 的大小，同时还将进行归一化处理。\n",
        "\n",
        "torchvision 支持对输入数据进行一些复杂的预处理/变换 （normalization, cropping, flipping, jittering 等）。具体可以参照 torchvision.tranforms 的官方文档说明。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9hHBU1RHVQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "vgg_format = transforms.Compose([\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "\n",
        "data_dir = './dogscats'\n",
        "\n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), vgg_format)\n",
        "         for x in ['train', 'valid']}\n",
        "\n",
        "dset_sizes = {x: len(dsets[x]) for x in ['train', 'valid']}\n",
        "dset_classes = dsets['train'].classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXTMyi8JMCy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 通过下面代码可以查看 dsets 的一些属性\n",
        "\n",
        "print(dsets['train'].classes)\n",
        "print(dsets['train'].class_to_idx)\n",
        "print(dsets['train'].imgs[:5])\n",
        "print('dset_sizes: ', dset_sizes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNxsgAsjOER1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader_train = torch.utils.data.DataLoader(dsets['train'], batch_size=64, shuffle=True, num_workers=6)\n",
        "loader_valid = torch.utils.data.DataLoader(dsets['valid'], batch_size=5, shuffle=False, num_workers=6)\n",
        "\n",
        "\n",
        "'''\n",
        "valid 数据一共有2000张图，每个batch是5张，因此，下面进行遍历一共会输出到 400\n",
        "同时，把第一个 batch 保存到 inputs_try, labels_try，分别查看\n",
        "'''\n",
        "count = 1\n",
        "for data in loader_valid:\n",
        "    print(count, end='\\n')\n",
        "    if count == 1:\n",
        "        inputs_try,labels_try = data\n",
        "    count +=1\n",
        "\n",
        "print(labels_try)\n",
        "print(inputs_try.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LJoaByuP8Ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 显示图片的小程序\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "#   Imshow for Tensor.\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = np.clip(std * inp + mean, 0,1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwRVAT65QF-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 显示 labels_try 的5张图片，即valid里第一个batch的5张图片\n",
        "out = torchvision.utils.make_grid(inputs_try)\n",
        "imshow(out, title=[dset_classes[x] for x in labels_try])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APTomKRsQ-A5",
        "colab_type": "text"
      },
      "source": [
        "## 3. 创建 VGG Model\n",
        "\n",
        "torchvision中集成了很多在 ImageNet （120万张训练数据） 上预训练好的通用的CNN模型，可以直接下载使用。\n",
        "\n",
        "在本课程中，我们直接使用预训练好的 VGG 模型。同时，为了展示 VGG 模型对本数据的预测结果，还下载了 ImageNet 1000 个类的 JSON 文件。\n",
        "\n",
        "在这部分代码中，对输入的5个图片利用VGG模型进行预测，同时，使用softmax对结果进行处理，随后展示了识别结果。可以看到，识别结果是比较非常准确的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ojrsIyrSQbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-RFHa-eRdom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg = models.vgg16(pretrained=True)\n",
        "\n",
        "with open('./imagenet_class_index.json') as f:\n",
        "    class_dict = json.load(f)\n",
        "dic_imagenet = [class_dict[str(i)][1] for i in range(len(class_dict))]\n",
        "\n",
        "inputs_try , labels_try = inputs_try.to(device), labels_try.to(device)\n",
        "model_vgg = model_vgg.to(device)\n",
        "\n",
        "outputs_try = model_vgg(inputs_try)\n",
        "\n",
        "print(outputs_try)\n",
        "print(outputs_try.shape)\n",
        "\n",
        "'''\n",
        "可以看到结果为5行，1000列的数据，每一列代表对每一种目标识别的结果。\n",
        "但是我也可以观察到，结果非常奇葩，有负数，有正数，\n",
        "为了将VGG网络输出的结果转化为对每一类的预测概率，我们把结果输入到 Softmax 函数\n",
        "'''\n",
        "m_softm = nn.Softmax(dim=1)\n",
        "probs = m_softm(outputs_try)\n",
        "vals_try,pred_try = torch.max(probs,dim=1)\n",
        "\n",
        "print( 'prob sum: ', torch.sum(probs,1))\n",
        "print( 'vals_try: ', vals_try)\n",
        "print( 'pred_try: ', pred_try)\n",
        "\n",
        "print([dic_imagenet[i] for i in pred_try.data])\n",
        "imshow(torchvision.utils.make_grid(inputs_try.data.cpu()), \n",
        "       title=[dset_classes[x] for x in labels_try.data.cpu()])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNkGMMiDWhiC",
        "colab_type": "text"
      },
      "source": [
        "## 4. 修改最后一层，冻结前面层的参数\n",
        "\n",
        "VGG 模型如下图所示，注意该网络由三种元素组成：\n",
        "\n",
        "- 卷积层（CONV）是发现图像中局部的 pattern\n",
        "- 全连接层（FC）是在全局上建立特征的关联\n",
        "- 池化（Pool）是给图像降维以提高特征的 invariance\n",
        "\n",
        "![VGG](http://fenggao-image.stor.sinaapp.com/20191006215625.jpg)\n",
        "\n",
        "我们的目标是使用预训练好的模型，因此，需要把最后的 nn.Linear 层由1000类，替换为2类。为了在训练中冻结前面层的参数，需要设置 required_grad=False。这样，反向传播训练梯度时，前面层的权重就不会自动更新了。训练中，只会更新最后一层的参数。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7k3Y46lXkTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model_vgg)\n",
        "\n",
        "model_vgg_new = model_vgg;\n",
        "\n",
        "for param in model_vgg_new.parameters():\n",
        "    param.requires_grad = False\n",
        "model_vgg_new.classifier._modules['6'] = nn.Linear(4096, 2)\n",
        "model_vgg_new.classifier._modules['7'] = torch.nn.LogSoftmax(dim = 1)\n",
        "\n",
        "model_vgg_new = model_vgg_new.to(device)\n",
        "\n",
        "print(model_vgg_new.classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8zMGZl3bAwd",
        "colab_type": "text"
      },
      "source": [
        "## 5. 训练并测试全连接层\n",
        "\n",
        "包括三个步骤：第1步，创建损失函数和优化器；第2步，训练模型；第3步，测试模型。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l6c_Pr1bZ3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "第一步：创建损失函数和优化器\n",
        "\n",
        "损失函数 NLLLoss() 的 输入 是一个对数概率向量和一个目标标签. \n",
        "它不会为我们计算对数概率，适合最后一层是log_softmax()的网络. \n",
        "'''\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# 学习率\n",
        "lr = 0.001\n",
        "\n",
        "# 随机梯度下降\n",
        "optimizer_vgg = torch.optim.SGD(model_vgg_new.classifier[6].parameters(),lr = lr)\n",
        "\n",
        "'''\n",
        "第二步：训练模型\n",
        "'''\n",
        "\n",
        "def train_model(model,dataloader,size,epochs=1,optimizer=None):\n",
        "    model.train()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        count = 0\n",
        "        for inputs,classes in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            classes = classes.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs,classes)           \n",
        "            optimizer = optimizer\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == classes.data)\n",
        "            count += len(inputs)\n",
        "            print('Training: No. ', count, ' process ... total: ', size)\n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.data.item() / size\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                     epoch_loss, epoch_acc))\n",
        "        \n",
        "        \n",
        "# 模型训练\n",
        "train_model(model_vgg_new,loader_train,size=dset_sizes['train'], epochs=1, \n",
        "            optimizer=optimizer_vgg)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJcnxVqvfyPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model,dataloader,size):\n",
        "    model.eval()\n",
        "    predictions = np.zeros(size)\n",
        "    all_classes = np.zeros(size)\n",
        "    all_proba = np.zeros((size,2))\n",
        "    i = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    for inputs,classes in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs,classes)           \n",
        "        _,preds = torch.max(outputs.data,1)\n",
        "        # statistics\n",
        "        running_loss += loss.data.item()\n",
        "        running_corrects += torch.sum(preds == classes.data)\n",
        "        predictions[i:i+len(classes)] = preds.to('cpu').numpy()\n",
        "        all_classes[i:i+len(classes)] = classes.to('cpu').numpy()\n",
        "        all_proba[i:i+len(classes),:] = outputs.data.to('cpu').numpy()\n",
        "        i += len(classes)\n",
        "        print('Testing: No. ', i, ' process ... total: ', size)        \n",
        "    epoch_loss = running_loss / size\n",
        "    epoch_acc = running_corrects.data.item() / size\n",
        "    print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                     epoch_loss, epoch_acc))\n",
        "    return predictions, all_proba, all_classes\n",
        "  \n",
        "predictions, all_proba, all_classes = test_model(model_vgg_new,loader_valid,size=dset_sizes['valid'])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0IbqeJJ7Y9E",
        "colab_type": "text"
      },
      "source": [
        "## 6. 可视化模型预测结果（主观分析）\n",
        "\n",
        "主观分析就是把预测的结果和相对应的测试图像输出出来看看，一般有四种方式：\n",
        "- 随机查看一些预测正确的图片\n",
        "- 随机查看一些预测错误的图片\n",
        "- 预测正确，同时具有较大的probability的图片\n",
        "- 预测错误，同时具有较大的probability的图片\n",
        "- 最不确定的图片，比如说预测概率接近0.5的图片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2S6HBAl808c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 单次可视化显示的图片个数\n",
        "n_view = 8\n",
        "correct = np.where(predictions==all_classes)[0]\n",
        "from numpy.random import random, permutation\n",
        "idx = permutation(correct)[:n_view]\n",
        "print('random correct idx: ', idx)\n",
        "loader_correct = torch.utils.data.DataLoader([dsets['valid'][x] for x in idx],\n",
        "                  batch_size = n_view,shuffle=True)\n",
        "for data in loader_correct:\n",
        "    inputs_cor,labels_cor = data\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs_cor)\n",
        "imshow(out, title=[l.item() for l in labels_cor])\n",
        "\n",
        "# 类似的思路，可以显示错误分类的图片，这里不再重复代码"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUylpS9_2xw",
        "colab_type": "text"
      },
      "source": [
        "## 7. 结论\n",
        "\n",
        "不知道大家发现没有，我们其实只是做了一个简单的 logistic regression！因此，我们实际上相当于是**杀鸡用了牛刀**（kill a fly with a sledge hammer）\n",
        "\n",
        "在我们这个代码示例中，sledge hammer 是在 ImageNet 上预训练好的 VGG 模型，在这个数据集中，有大量猫和狗的图片。同时，我们也发现，即使不修改网络，模型也可以非常准确的识别猫和狗。\n",
        "\n",
        "我们学习了冻结前面层，只训练最后的一个 linear layer 中的 8194 个参数 （bias $2\\times 4096+2$）。这么一个简单的任务，使用 CPU 训练也是完全可以的。\n",
        "\n",
        "这个代码示例是非常有启发意义的（instructive），这个实验相当 instructive ，因为它展示的是如何在工程问题中使用深度学习：首先准备待解决问题的数据，然后下载预训练好的网络，接着用准备好的数据来 fine-tune 预训练好的网络。这些步骤在任何深度学习工程项目中都是如此。\n",
        "\n",
        "最后，期待大家  have fun with the network and understanding the learning process!"
      ]
    }
  ]
}
