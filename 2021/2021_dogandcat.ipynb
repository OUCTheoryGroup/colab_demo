{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_dogandcat.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJIRlhT7Yzuf"
      },
      "source": [
        "# 2021级新生学习：用 LeNet 网络进行猫狗大战\n",
        "\n",
        "本周布置的猫狗大战的作业，是我自己拍脑袋想的。、我发现大多同学做的并太理想，主要原因是因为对pytorch不太熟悉。中秋假期我也做了这个作业，效果虽然并不算好，但可以做为一个范例提供给初学者学习。\n",
        "\n",
        "大家普遍反映有两个问题：1、网络不收敛；2、Colab上训练时间太长。\n",
        "\n",
        "**问题1解决方法：** 网络不收敛，可以使用更深的网络。网络变深时，sigmoid 激活函数容易进入饱和区，就不收敛了，要把激活函数替换为 ReLU 。另外，大家可以把优化器由 SGD 替换为 Adam ，一般情况下，我认为 Adam 效果会比 SGD 好一些。具体原因大家可以自己补课，这里不多说。\n",
        "\n",
        "**问题2解决方法：** 训练时间长还是因为数据量大，这里我采取策略是选择较少的训练样本，猫狗各取了2000个，训练时间会大大缩短。（总体思路还是先保证代码能够跑起来，实际需要的话，再放到服务器上跑）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAZptktWGbb-"
      },
      "source": [
        "# 这个是训练集，猫狗各取了2000个\n",
        "! wget https://gaopursuit.oss-cn-beijing.aliyuncs.com/2021/files/train.zip\n",
        "! unzip train.zip\n",
        "\n",
        "# 这个是测试集\n",
        "! wget https://gaopursuit.oss-cn-beijing.aliyuncs.com/202007/dogs_cats_test.zip\n",
        "! unzip dogs_cats_test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuCycdrVHNIl",
        "outputId": "d81041d0-896f-45e2-bcbc-9f58c1951524"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "import json, random\n",
        "import os\n",
        "\n",
        "\n",
        "# 判断是否存在GPU设备\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())\n",
        "\n",
        "# 训练图片和测试图片的路径\n",
        "train_path = './train/'\n",
        "test_path = './test/'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using gpu: True \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0fxWCV5cxCn"
      },
      "source": [
        "创建数据集，这里采用了 齐昊 的代码。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnHL4UxNLe7p"
      },
      "source": [
        "\n",
        "def get_data(file_path):\n",
        "    file_lst = os.listdir(file_path) #获得所有文件名称 xxxx.jpg\n",
        "    data_lst = []\n",
        "    for i in range(len(file_lst)):\n",
        "        clas = file_lst[i][:3] #cat和dog在文件名的开头\n",
        "        img_path = os.path.join(file_path,file_lst[i])#将文件名与路径合并得到完整路径，以备读取\n",
        "        if clas == 'cat':\n",
        "            data_lst.append((img_path, 0))\n",
        "        else:\n",
        "            data_lst.append((img_path, 1))\n",
        "    return data_lst\n",
        "\n",
        "class catdog_set(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, transform):\n",
        "        super(catdog_set).__init__()\n",
        "        self.data_lst = get_data(path)#调用刚才的函数获得数据列表\n",
        "        self.trans = torchvision.transforms.Compose(transform)\n",
        "    def __len__(self):\n",
        "        return len(self.data_lst)\n",
        "    def __getitem__(self,index):\n",
        "        (img,cls) = self.data_lst[index]\n",
        "        image = self.trans(Image.open(img))\n",
        "        label = torch.tensor(cls,dtype=torch.float32)\n",
        "        return image,label\n",
        "\n",
        "# 将输入图像缩放为 128*128，每一个 batch 中图像数量为128\n",
        "# 训练时，每一个 epoch 随机打乱图像的顺序，以实现样本多样化\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    catdog_set(train_path, [transforms.Resize((128,128)),transforms.ToTensor()]), \n",
        "    batch_size=128, shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXTfzO2Ic7ci"
      },
      "source": [
        "这里是网络的定义，下面附有一段测试代码，因为输入图像是 3x128x128，可以看到网络的处理为：\n",
        "\n",
        "3x128x128 ==> conv1( 6x124x124 ==> 6x62x62 )\n",
        "\n",
        "==> conv2( 16x58x58 ==> 16x29x29 )\n",
        "\n",
        "==> conv3( 32x26x26 ==> 32x13x13 )\n",
        "\n",
        "==> conv4( 32x10x10 ==> 32x5x5 )\n",
        "\n",
        "==> conv5( 32x1x1 ==> 32)\n",
        "\n",
        "==> 32 ==> 16 ==> 2\n",
        "\n",
        "可以在 forward 函数中加一些 print 函数测试，观察 feature map 形状的变化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKKtN-J5Hodw"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.conv3 = nn.Conv2d(16, 32, 4)\n",
        "        self.conv4 = nn.Conv2d(32, 32, 4)\n",
        "        self.conv5 = nn.Conv2d(32, 32, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32, 16)\n",
        "        self.fc2 = nn.Linear(16, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = x.view(-1, 32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x), dim=1)\n",
        "        return x\n",
        "\n",
        "# 随机输入，测试网络结构是否通\n",
        "# x = torch.randn(1, 3, 128, 128)\n",
        "# net = Net()\n",
        "# y = net(x)\n",
        "# print(y.shape)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uAFkWXgeRz3"
      },
      "source": [
        "网络训练准备，三个要素：1、将网络放到 GPU 上；2、定义损失函数；3、定义优化器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASrMg2SqMQsw"
      },
      "source": [
        "# 网络放到GPU上\n",
        "net = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnPYWLCdegP2"
      },
      "source": [
        "开始训练，这里是训练30个 epoch。训练过程中，首先梯度归零，然后正向传播 + 计算损失 + 反向传播 + 优化。所有的网络训练都是这个过程。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkQ6G_5dL5J8",
        "outputId": "dfd8c53c-5e60-445e-f981-1b196356cb83"
      },
      "source": [
        "for epoch in range(30):  # 重复多轮训练\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 优化器梯度归零\n",
        "        optimizer.zero_grad()\n",
        "        # 正向传播 +　反向传播 + 优化 \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "    print('Epoch: %d loss: %.6f' %(epoch + 1, loss.item()))\n",
        "print('Finished Training')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 loss: 0.693591\n",
            "Epoch: 2 loss: 0.691867\n",
            "Epoch: 3 loss: 0.682191\n",
            "Epoch: 4 loss: 0.657503\n",
            "Epoch: 5 loss: 0.705427\n",
            "Epoch: 6 loss: 0.660462\n",
            "Epoch: 7 loss: 0.634173\n",
            "Epoch: 8 loss: 0.673097\n",
            "Epoch: 9 loss: 0.593748\n",
            "Epoch: 10 loss: 0.525426\n",
            "Epoch: 11 loss: 0.550043\n",
            "Epoch: 12 loss: 0.583569\n",
            "Epoch: 13 loss: 0.669047\n",
            "Epoch: 14 loss: 0.532821\n",
            "Epoch: 15 loss: 0.591107\n",
            "Epoch: 16 loss: 0.512886\n",
            "Epoch: 17 loss: 0.551087\n",
            "Epoch: 18 loss: 0.574038\n",
            "Epoch: 19 loss: 0.604391\n",
            "Epoch: 20 loss: 0.552344\n",
            "Epoch: 21 loss: 0.493089\n",
            "Epoch: 22 loss: 0.442594\n",
            "Epoch: 23 loss: 0.584947\n",
            "Epoch: 24 loss: 0.496618\n",
            "Epoch: 25 loss: 0.462232\n",
            "Epoch: 26 loss: 0.384848\n",
            "Epoch: 27 loss: 0.506766\n",
            "Epoch: 28 loss: 0.488330\n",
            "Epoch: 29 loss: 0.462068\n",
            "Epoch: 30 loss: 0.462078\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGAQPNGke4KB"
      },
      "source": [
        "测试集包括2000张图片，一张张图片读取，输入网络预测结果，最后将训练结果写入文件。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THCKK-lPVJvQ"
      },
      "source": [
        "resfile = open('res.csv', 'w')\n",
        "\n",
        "for i in range(0,2000): \n",
        "    img_PIL = Image.open('./test/'+str(i)+'.jpg')\n",
        "    img_tensor = transforms.Compose([transforms.Resize((128,128)),transforms.ToTensor()])(img_PIL)\n",
        "    img_tensor = img_tensor.reshape(-1, img_tensor.shape[0], img_tensor.shape[1], img_tensor.shape[2])\n",
        "    img_tensor = img_tensor.to(device)\n",
        "    out = net(img_tensor).cpu().detach().numpy()\n",
        "    if out[0, 0] < out[0, 1]:\n",
        "        resfile.write(str(i)+','+str(1)+'\\n')\n",
        "    else:\n",
        "        resfile.write(str(i)+','+str(0)+'\\n')\n",
        "\n",
        "resfile.close()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD4xnQyyfjtO"
      },
      "source": [
        "第一次测试，结果是 68.45 。第二次把 batch size 由 64 修改为了 128，准确率上升到了 74.6，也许还有其他方法，大家自己研究吧。"
      ]
    }
  ]
}