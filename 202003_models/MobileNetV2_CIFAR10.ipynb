{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OUCTheoryGroup/colab_demo/blob/master/MobileNetV2_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyx9j3WEsCVq",
        "colab_type": "text"
      },
      "source": [
        "## MobileNet V2\n",
        "\n",
        "论文：MobileNetV2: Inverted Residuals and Linear Bottlenecks, *CVPR* 2018\n",
        "\n",
        "**MobileNet V1 的主要问题：** 结构非常简单，但是没有使用RestNet里的residual learning；另一方面，Depthwise Conv确实是大大降低了计算量，但实际中，发现不少训练出来的kernel是空的。\n",
        "\n",
        "**MobileNet V2 的主要改动一：设计了Inverted residual block**\n",
        "\n",
        "![替代文字](http://q6dz4bbgt.bkt.clouddn.com/20200309092536334.jpg)\n",
        "\n",
        "ResNet中的bottleneck，先用1x1卷积把通道数由256降到64，然后进行3x3卷积，不然中间3x3卷积计算量太大。所以bottleneck是两边宽中间窄（也是名字的由来）。\n",
        "\n",
        "现在我们中间的3x3卷积可以变成Depthwise，计算量很少了，所以通道可以多一些。所以MobileNet V2 先用1x1卷积提升通道数，然后用Depthwise 3x3的卷积，再使用1x1的卷积降维。作者称之为Inverted residual block，中间宽两边窄。\n",
        "\n",
        "**MobileNet V2 的主要改动二：去掉输出部分的ReLU6**\n",
        "\n",
        "在 MobileNet V1 里面使用 ReLU6，ReLU6 就是普通的ReLU但是限制最大输出值为 6，这是为了在移动端设备 float16/int8 的低精度的时候，也能有很好的数值分辨率。Depthwise输出比较浅，应用ReLU会带来信息损失，所以在最后把ReLU去掉了（注意下图中标红的部分没有ReLU）。\n",
        "\n",
        "![替代文字](http://q6dz4bbgt.bkt.clouddn.com/20200309142715231.jpg)\n",
        "\n",
        "下面就是 Inverted residual block 部分的代码，主要思路就是:\n",
        "\n",
        "expand + Depthwise + Pointwise 其中，expand就是增大feature map数量的意思。需要指出的是，当步长为1的时候，要加一个 shortcut；步长为2的时候，目的是降低feature map尺寸，就不需要加 shortcut 了。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhpe8ufGr-Jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "class Block(nn.Module):\n",
        "    '''expand + depthwise + pointwise'''\n",
        "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
        "        super(Block, self).__init__()\n",
        "        self.stride = stride\n",
        "        # 通过 expansion 增大 feature map 的数量\n",
        "        planes = expansion * in_planes\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
        "\n",
        "        # 步长为 1 时，如果 in 和 out 的 feature map 通道不同，用一个卷积改变通道数\n",
        "        if stride == 1 and in_planes != out_planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_planes))\n",
        "        # 步长为 1 时，如果 in 和 out 的 feature map 通道相同，直接返回输入\n",
        "        if stride == 1 and in_planes == out_planes:\n",
        "            self.shortcut = nn.Sequential()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        # 步长为1，加 shortcut 操作\n",
        "        if self.stride == 1:\n",
        "            return out + self.shortcut(x)\n",
        "        # 步长为2，直接输出\n",
        "        else:\n",
        "            return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb_-Z17Eu-GY",
        "colab_type": "text"
      },
      "source": [
        "## 创建 MobileNetV2 网络\n",
        "\n",
        "注意，因为 CIFAR10 是 32*32，因此，网络有一定修改。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s_SAyhnvEXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MobileNetV2(nn.Module):\n",
        "    # (expansion, out_planes, num_blocks, stride)\n",
        "    cfg = [(1,  16, 1, 1),\n",
        "           (6,  24, 2, 1), \n",
        "           (6,  32, 3, 2),\n",
        "           (6,  64, 4, 2),\n",
        "           (6,  96, 3, 1),\n",
        "           (6, 160, 3, 2),\n",
        "           (6, 320, 1, 1)]\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layers = self._make_layers(in_planes=32)\n",
        "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(1280)\n",
        "        self.linear = nn.Linear(1280, num_classes)\n",
        "\n",
        "    def _make_layers(self, in_planes):\n",
        "        layers = []\n",
        "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
        "            strides = [stride] + [1]*(num_blocks-1)\n",
        "            for stride in strides:\n",
        "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
        "                in_planes = out_planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layers(out)\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBLkv5BBuuaE",
        "colab_type": "text"
      },
      "source": [
        "## 创建 DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmJhJ7C2uyvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 使用GPU训练，可以在菜单 \"代码执行工具\" -> \"更改运行时类型\" 里进行设置\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,  download=True, transform=transform_train)\n",
        "testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV1gTYo6YYl9",
        "colab_type": "text"
      },
      "source": [
        "实例化网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr03keecYaJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 网络放到GPU上\n",
        "net = MobileNetV2().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On2sLtOCYRMP",
        "colab_type": "text"
      },
      "source": [
        "## 模型训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJB0a7J-YSv8",
        "colab_type": "code",
        "outputId": "c779d80c-fca8-4690-8cad-29635c73875f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "for epoch in range(10):  # 重复多轮训练\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # 优化器梯度归零\n",
        "        optimizer.zero_grad()\n",
        "        # 正向传播 +　反向传播 + 优化 \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # 输出统计信息\n",
        "        if i % 100 == 0:   \n",
        "            print('Epoch: %d Minibatch: %5d loss: %.3f' %(epoch + 1, i + 1, loss.item()))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Minibatch:     1 loss: 2.309\n",
            "Epoch: 1 Minibatch:   101 loss: 1.566\n",
            "Epoch: 1 Minibatch:   201 loss: 1.462\n",
            "Epoch: 1 Minibatch:   301 loss: 1.226\n",
            "Epoch: 2 Minibatch:     1 loss: 1.218\n",
            "Epoch: 2 Minibatch:   101 loss: 1.381\n",
            "Epoch: 2 Minibatch:   201 loss: 1.089\n",
            "Epoch: 2 Minibatch:   301 loss: 1.117\n",
            "Epoch: 3 Minibatch:     1 loss: 1.056\n",
            "Epoch: 3 Minibatch:   101 loss: 0.964\n",
            "Epoch: 3 Minibatch:   201 loss: 0.877\n",
            "Epoch: 3 Minibatch:   301 loss: 1.126\n",
            "Epoch: 4 Minibatch:     1 loss: 0.841\n",
            "Epoch: 4 Minibatch:   101 loss: 0.734\n",
            "Epoch: 4 Minibatch:   201 loss: 0.775\n",
            "Epoch: 4 Minibatch:   301 loss: 0.738\n",
            "Epoch: 5 Minibatch:     1 loss: 0.739\n",
            "Epoch: 5 Minibatch:   101 loss: 0.812\n",
            "Epoch: 5 Minibatch:   201 loss: 0.708\n",
            "Epoch: 5 Minibatch:   301 loss: 0.544\n",
            "Epoch: 6 Minibatch:     1 loss: 0.769\n",
            "Epoch: 6 Minibatch:   101 loss: 0.683\n",
            "Epoch: 6 Minibatch:   201 loss: 0.486\n",
            "Epoch: 6 Minibatch:   301 loss: 0.583\n",
            "Epoch: 7 Minibatch:     1 loss: 0.559\n",
            "Epoch: 7 Minibatch:   101 loss: 0.596\n",
            "Epoch: 7 Minibatch:   201 loss: 0.496\n",
            "Epoch: 7 Minibatch:   301 loss: 0.587\n",
            "Epoch: 8 Minibatch:     1 loss: 0.389\n",
            "Epoch: 8 Minibatch:   101 loss: 0.501\n",
            "Epoch: 8 Minibatch:   201 loss: 0.460\n",
            "Epoch: 8 Minibatch:   301 loss: 0.579\n",
            "Epoch: 9 Minibatch:     1 loss: 0.618\n",
            "Epoch: 9 Minibatch:   101 loss: 0.330\n",
            "Epoch: 9 Minibatch:   201 loss: 0.418\n",
            "Epoch: 9 Minibatch:   301 loss: 0.460\n",
            "Epoch: 10 Minibatch:     1 loss: 0.416\n",
            "Epoch: 10 Minibatch:   101 loss: 0.475\n",
            "Epoch: 10 Minibatch:   201 loss: 0.465\n",
            "Epoch: 10 Minibatch:   301 loss: 0.600\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIDFPkozZeBS",
        "colab_type": "text"
      },
      "source": [
        "## 模型测试"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv1u01EGZgMp",
        "colab_type": "code",
        "outputId": "2bfd06c6-9f89-431f-d794-763aaaa66d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 82.13 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}